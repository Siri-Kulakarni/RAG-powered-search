{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing and Importing Necessary Libraries"
      ],
      "metadata": {
        "id": "CYVxkZB4bBlP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQSo5F5If-s_"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FldU5a7WvvZQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain-google-genai\n",
        "!pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnnIPSJChAgV"
      },
      "outputs": [],
      "source": [
        "!pip install -q unstructured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7KOOB_QXDyg"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNqFgirsayQI"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q gnews"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q text-generation transformers google-search-results numexpr langchainhub sentencepiece jinja2"
      ],
      "metadata": {
        "id": "RVERvBpObSlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrZOmL5tHy2R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from gnews import GNews\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = \"\" # Enter your Gemini API key."
      ],
      "metadata": {
        "id": "8kXB9LbjbXq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieving Latest News"
      ],
      "metadata": {
        "id": "uG52inicbZej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wjw9S9kH2TL"
      },
      "outputs": [],
      "source": [
        "def get_title_and_content(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        title = soup.title.string if soup.title else \"No title found\"\n",
        "        content = '\\n'.join([p.get_text() for p in soup.find_all('p')])\n",
        "        return title, content\n",
        "\n",
        "    else:\n",
        "        print(\"Failed to fetch URL:\", url)\n",
        "        return None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DclwSu8NH4fu"
      },
      "outputs": [],
      "source": [
        "def pretty_print(text, width = 80):\n",
        "    lines = textwrap.wrap(text, width=width)\n",
        "    return '\\n'.join(lines)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic = '' # Enter your topic of interest such as Artificial Intelligence, Natural Language Processing, etc."
      ],
      "metadata": {
        "id": "j-dW3uY6bkbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHwE8ufJH7Du",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "google_news = GNews()\n",
        "news = google_news.get_news(topic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i2lITchayQL"
      },
      "outputs": [],
      "source": [
        "data_directory = \"data\"\n",
        "if not os.path.exists(data_directory):\n",
        "    os.makedirs(data_directory)\n",
        "\n",
        "stored_urls = []\n",
        "count = 1\n",
        "files_saved = 0\n",
        "while files_saved < 10:\n",
        "    file_path = os.path.join(data_directory, f\"{topic} - {files_saved + 1}.txt\")\n",
        "    title, content = get_title_and_content(news[count - 1][\"url\"])\n",
        "    if title and content:\n",
        "        with open(file_path, \"a\") as f:\n",
        "            f.write(\"Title: \" + title + \"\\n\")\n",
        "            f.write(\"Content: \" + content + \"\\n\")\n",
        "            stored_urls.append(news[count - 1][\"url\"])\n",
        "        files_saved += 1\n",
        "    count += 1\n",
        "\n",
        "print(\"Files saved successfully.\")\n",
        "\n",
        "print(\"Stored URLs:\")\n",
        "for url in stored_urls:\n",
        "    print(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG-based Query"
      ],
      "metadata": {
        "id": "8hmgDGLWb6TH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZK11kfVVffO2"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.vectorstores.chroma import Chroma\n",
        "from langchain.llms import OpenAI\n",
        "import getpass\n",
        "import shutil\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
        "\n",
        "CHROMA_PATH = \"chroma\" # Change this everytime you run this cell again\n",
        "DATA_PATH = r\"data\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    generate_data_store()\n",
        "\n",
        "\n",
        "def generate_data_store():\n",
        "    documents = load_documents()\n",
        "    chunks = split_text(documents)\n",
        "    save_to_chroma(chunks)\n",
        "\n",
        "\n",
        "def load_documents():\n",
        "    loader = DirectoryLoader(DATA_PATH, glob=\"*.txt\")\n",
        "    documents = loader.load()\n",
        "    return documents\n",
        "\n",
        "\n",
        "def split_text(documents: list[Document]):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100,\n",
        "                                                   length_function = len, add_start_index = True)\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
        "\n",
        "    document = chunks[1]\n",
        "    print(document.page_content)\n",
        "    print(document.metadata)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def save_to_chroma(chunks: list[Document]):\n",
        "    if os.path.exists(CHROMA_PATH):\n",
        "        shutil.rmtree(CHROMA_PATH)\n",
        "\n",
        "    db = Chroma.from_documents(chunks, embeddings, persist_directory = CHROMA_PATH)\n",
        "    db.persist()\n",
        "    print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = \"\" # Enter your query"
      ],
      "metadata": {
        "id": "5V5xXm4ncg0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2ieHMAuh1kp"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from langchain.vectorstores.chroma import Chroma\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Please consider the following information as the background for your response. Ensure that your answer is relevant to the details provided in this context.\n",
        "\n",
        "{context}\n",
        "\n",
        "---\n",
        "\n",
        "Here is the specific inquiry you are tasked with addressing. Make sure your response directly addresses this question and utilizes the information provided in the context.\n",
        "\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "db = Chroma(persist_directory = CHROMA_PATH, embedding_function = embeddings)\n",
        "\n",
        "results = db.similarity_search_with_relevance_scores(query_text, k = 4)\n",
        "if len(results) == 0 or results[0][1] < 0.7:\n",
        "    print(f\"Unable to find matching results.\")\n",
        "\n",
        "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
        "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "prompt = prompt_template.format(context=context_text, question=query_text)\n",
        "\n",
        "model = GoogleGenerativeAI(model = \"gemini-pro\", max_output_tokens = 1024,\n",
        "                           google_api_key = os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "response_text = model.invoke(prompt)\n",
        "\n",
        "sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
        "formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
        "print(formatted_response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CYVxkZB4bBlP",
        "uG52inicbZej"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}